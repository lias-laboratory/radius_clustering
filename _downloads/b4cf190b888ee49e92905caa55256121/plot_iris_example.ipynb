{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Iris Dataset Clustering Example\n\nThis example is meant to illustrate the use of the Radius clustering library on the Iris dataset.\nIt comes with a simple example of how to use the library to cluster the Iris dataset and a comparison with\nkmeans clustering algorithms.\n\nThe example includes:\n1. Loading the Iris dataset\n2. Applying Radius clustering and k-means clustering\n3. Visualizing the clustering results\n\nThis example serves as a simple introduction to using the Radius clustering library\non a well-known dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Haenn Quentin\n# SPDX-License-Identifier: MIT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the Iris dataset\n\nWe start by loading the Iris dataset using the `fetch_openml` function from `sklearn.datasets`.\nThe Iris dataset is a well-known dataset that contains 150 samples of iris flowers.\nEach sample has 4 features: sepal length, sepal width, petal length, and petal width.\nThe dataset is labeled with 3 classes: setosa, versicolor, and virginica.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom sklearn import datasets\nfrom radius_clustering import RadiusClustering\n\n# Load the Iris dataset\niris = datasets.load_iris()\nX = iris[\"data\"]\ny = iris.target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize the Iris dataset\n\nWe can visualize the Iris dataset by plotting the dataset. We use PCA to reduce the dimensionality to 3D\nand plot the dataset in a 3D scatter plot.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nimport mpl_toolkits.mplot3d\n\n# Reduce the dimensionality of the dataset to 3D using PCA\npca = PCA(n_components=3)\niris_reduced = pca.fit_transform(X)\nfig = plt.figure(figsize=(8, 6))\nax = fig.add_subplot(111, projection=\"3d\", elev=48, azim=134)\nax.scatter(\n    iris_reduced[:, 0],\n    iris_reduced[:, 1],\n    iris_reduced[:, 2],\n    c=y,\n    cmap=\"Dark2\",\n    s=40,\n)\n# Set plot labels\nax.set_title(\"Iris dataset in first 3 PCA components\")\nax.set_xlabel(\"1st eigenvector\")\nax.set_ylabel(\"2nd eigenvector\")\nax.set_zlabel(\"3rd eigenvector\")\n\n# Hide tick labels\nax.xaxis.set_ticklabels([])\nax.yaxis.set_ticklabels([])\nax.zaxis.set_ticklabels([])\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute Clustering with Radius Clustering\n\nWe can now apply Radius clustering to the Iris dataset.\nWe create an instance of the `RadiusClustering` class and fit it to the Iris dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\n\nrad = RadiusClustering(manner=\"exact\", threshold=1.43)\nt0 = time.time()\nrad.fit(X)\nt_rad = time.time() - t0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute KMeans Clustering for Comparison\n\nWe can also apply KMeans clustering to the Iris dataset for comparison.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n\nk_means = KMeans(n_clusters=3, n_init=10)\nt0 = time.time()\nk_means.fit(X)\nt_kmeans = time.time() - t0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--------------------------------------\n\nWe want to have the same color for the same cluster in both plots.\nWe can achieve this by matching the cluster labels of the Radius clustering and the KMeans clustering.\nFirst we define a function to retrieve the cluster centers from the Radius clustering and KMeans clustering and\nmatch them pairwise.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_order_labels(kmeans, rad, data):\n    centers1_cpy = kmeans.cluster_centers_.copy()\n    centers2_cpy = data[rad.centers_].copy()\n    order = []\n    # For each center in the first clustering, find the closest center in the second clustering\n    for center in centers1_cpy:\n        match = pairwise_distances_argmin([center], centers2_cpy)\n        # if there is only one center left, assign it to the last cluster label not yet assigned\n        if len(centers2_cpy) == 1:\n            for i in range(len(centers1_cpy)):\n                if i not in order:\n                    order.append(i)\n                    break\n            break\n        # get coordinates of the center in the second clustering\n        coordinates = centers2_cpy[match]\n        # find the closest point in the data to the center to get the cluster label\n        closest_point = pairwise_distances_argmin(coordinates, data)\n        match_label = rad.labels_[closest_point]\n        # remove the center from the second clustering\n        centers2_cpy = np.delete(centers2_cpy, match, axis=0)\n        # add the cluster label to the order\n        order.append(int(match_label[0]))\n    return order\n\n\nfrom sklearn.metrics.pairwise import pairwise_distances_argmin\n\nrad_centers_index = np.array(rad.centers_)\norder = get_order_labels(k_means, rad, X)\n\nkmeans_centers = k_means.cluster_centers_\nrad_centers = rad_centers_index[order]\nrad_centers_coordinates = X[rad_centers]\n\n# Pair the cluster labels\nkmeans_labels = pairwise_distances_argmin(X, kmeans_centers)\nrad_labels = pairwise_distances_argmin(X, rad_centers_coordinates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting the results and the difference\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(12, 6))\nfig.subplots_adjust(left=0.02, right=0.98, bottom=0.05, top=0.9)\ncolors = [\"#4EACC5\", \"#FF9C34\", \"#4E9A06\"]\n\n# KMeans\nax = fig.add_subplot(1, 3, 1, projection=\"3d\", elev=48, azim=134, roll=0)\n\nax.scatter(\n    iris_reduced[:, 0],\n    iris_reduced[:, 1],\n    iris_reduced[:, 2],\n    c=kmeans_labels,\n    cmap=\"Dark2\",\n    s=40,\n)\n# adapting center coordinates to the 3D plot\nkmeans_centers = pca.transform(kmeans_centers)\nax.scatter(\n    kmeans_centers[:, 0],\n    kmeans_centers[:, 1],\n    kmeans_centers[:, 2],\n    c=\"r\",\n    s=200,\n)\nax.set_title(\"KMeans\")\nax.set_xticks(())\nax.set_yticks(())\nax.set_zticks(())\n\nax.text3D(-3.5, 3, 1.0, \"train time: %.2fs\\ninertia: %f\" % (t_kmeans, k_means.inertia_))\n\n# MDS\nax = fig.add_subplot(1, 3, 2, projection=\"3d\", elev=48, azim=134, roll=0)\nax.scatter(\n    iris_reduced[:, 0],\n    iris_reduced[:, 1],\n    iris_reduced[:, 2],\n    c=rad_labels,\n    cmap=\"Dark2\",\n    s=40,\n)\n# adapting center coordinates to the 3D plot\nrad_centers_coordinates = pca.transform(rad_centers_coordinates)\nax.scatter(\n    rad_centers_coordinates[:, 0],\n    rad_centers_coordinates[:, 1],\n    rad_centers_coordinates[:, 2],\n    c=\"r\",\n    s=200,\n)\nax.set_title(\"MDS Clustering\")\nax.set_xticks(())\nax.set_yticks(())\nax.set_zticks(())\nax.text3D(-3.5, 3, 0.0, \"train time: %.2fs\" % t_rad)\n\n# Initialize the different array to all False\ndifferent = rad_labels == 4\nax = fig.add_subplot(1, 3, 3, projection=\"3d\", elev=48, azim=134, roll=0)\n\nfor k in range(3):\n    different += (kmeans_labels == k) != (rad_labels == k)\n\nidentical = np.logical_not(different)\nax.scatter(\n    iris_reduced[identical, 0], iris_reduced[identical, 1], color=\"#bbbbbb\", marker=\".\"\n)\nax.scatter(iris_reduced[different, 0], iris_reduced[different, 1], color=\"m\")\nax.set_title(\"Difference\")\nax.set_xticks(())\nax.set_yticks(())\nax.set_zticks(())\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Another difference plot\n\nAs we saw, the difference plot is not very informative using Iris.\nWe'll use a different dataset to show the difference plot.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "wine = datasets.load_wine()\nX = wine.data\ny = wine.target\npca = PCA(n_components=3)\nwine_reduced = pca.fit_transform(X)\n\n# Compute clustering with MDS\n\nrad = RadiusClustering(manner=\"exact\", threshold=232.09)\nt0 = time.time()\nrad.fit(X)\nt_rad = time.time() - t0\n\n# Compute KMeans clustering for comparison\n\nk_means = KMeans(n_clusters=3, n_init=10)\nt0 = time.time()\nk_means.fit(X)\nt_kmeans = time.time() - t0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reapllying the same process as before\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rad_centers_index = np.array(rad.centers_)\norder = get_order_labels(k_means, rad, X)\n\nkmeans_centers = k_means.cluster_centers_\nrad_centers = rad_centers_index[order]\nrad_centers_coordinates = X[rad_centers]\n\n# Pair the cluster labels\nkmeans_labels = pairwise_distances_argmin(X, kmeans_centers)\nrad_labels = pairwise_distances_argmin(X, rad_centers_coordinates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting the results and the difference\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(12, 6))\nfig.subplots_adjust(left=0.02, right=0.98, bottom=0.05, top=0.9)\ncolors = [\"#4EACC5\", \"#FF9C34\", \"#4E9A06\"]\n\n# KMeans\nax = fig.add_subplot(1, 3, 1, projection=\"3d\", elev=48, azim=134, roll=0)\n\nax.scatter(\n    wine_reduced[:, 0],\n    wine_reduced[:, 1],\n    wine_reduced[:, 2],\n    c=kmeans_labels,\n    cmap=\"Dark2\",\n    s=40,\n)\n# adapting center coordinates to the 3D plot\nkmeans_centers = pca.transform(kmeans_centers)\nax.scatter(\n    kmeans_centers[:, 0],\n    kmeans_centers[:, 1],\n    kmeans_centers[:, 2],\n    c=\"r\",\n    s=200,\n)\nax.set_title(\"KMeans\")\nax.set_xticks(())\nax.set_yticks(())\nax.set_zticks(())\n\nax.text3D(\n    60.0, 80.0, 0.0, \"train time: %.2fs\\ninertia: %f\" % (t_kmeans, k_means.inertia_)\n)\n\n# MDS\nax = fig.add_subplot(1, 3, 2, projection=\"3d\", elev=48, azim=134, roll=0)\nax.scatter(\n    wine_reduced[:, 0],\n    wine_reduced[:, 1],\n    wine_reduced[:, 2],\n    c=rad_labels,\n    cmap=\"Dark2\",\n    s=40,\n)\n# adapting center coordinates to the 3D plot\nrad_centers_coordinates = pca.transform(rad_centers_coordinates)\nax.scatter(\n    rad_centers_coordinates[:, 0],\n    rad_centers_coordinates[:, 1],\n    rad_centers_coordinates[:, 2],\n    c=\"r\",\n    s=200,\n)\nax.set_title(\"MDS Clustering\")\nax.set_xticks(())\nax.set_yticks(())\nax.set_zticks(())\nax.text3D(60.0, 80.0, 0.0, \"train time: %.2fs\" % t_rad)\n\n# Initialize the different array to all False\ndifferent = rad_labels == 4\nax = fig.add_subplot(1, 3, 3, projection=\"3d\", elev=48, azim=134, roll=0)\n\nfor k in range(3):\n    different += (kmeans_labels == k) != (rad_labels == k)\n\nidentical = np.logical_not(different)\nax.scatter(\n    wine_reduced[identical, 0], wine_reduced[identical, 1], color=\"#bbbbbb\", marker=\".\"\n)\nax.scatter(wine_reduced[different, 0], wine_reduced[different, 1], color=\"m\")\nax.set_title(\"Difference\")\nax.set_xticks(())\nax.set_yticks(())\nax.set_zticks(())\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n\nIn this example, we applied Radius clustering to the Iris and Wine datasets and compared it with KMeans clustering.\nWe visualized the clustering results and the difference between the two clustering algorithms.\nWe saw that Radius Clustering can lead to smaller clusters than kmeans, which produces much more equilibrate clusters.\nThe difference plot can be very useful to see where the two clustering algorithms differ.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}